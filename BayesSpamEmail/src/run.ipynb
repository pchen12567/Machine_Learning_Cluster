{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import SpamEmailBayes class\n",
    "from spamEmail import SpamEmailBayes\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SpamEmailBayes instance\n",
    "spam = SpamEmailBayes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init dictory to save words and amount\n",
    "spamDict = {}\n",
    "normDict = {}\n",
    "testDict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init storege to save words in each email\n",
    "wordsList = []\n",
    "wordsDict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init test result dictory\n",
    "# Set file name as the key and category as the value\n",
    "testResult = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the normal, spam and test email file name list\n",
    "normFileList = spam.get_file_list('../data/normal/')\n",
    "spamFileList = spam.get_file_list('../data/spam')\n",
    "testFileList = spam.get_file_list('../data/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of noramla and spam email\n",
    "normFileLen = len(normFileList)\n",
    "spamFileLen = len(spamFileList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the stop words list\n",
    "stop_list = spam.get_stop_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/jc/l9vx9tp979g0tm976wjrgwkr0000gn/T/jieba.cache\n",
      "Loading model cost 0.863 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "# Get the word frequence in normal email\n",
    "for file_name in normFileList:\n",
    "    wordsList.clear()\n",
    "    with open('../data/normal/' + file_name, 'r', encoding='gbk') as f:\n",
    "        content = f.read()\n",
    "        for line in content:\n",
    "            rule = re.compile(u'[^\\u4E00-\\u9FA5]')\n",
    "            line = rule.sub(r'', line)\n",
    "            spam.get_word_list(line, wordsList, stop_list)\n",
    "    \n",
    "    spam.addToDict(wordsList, wordsDict)\n",
    "\n",
    "normDict = wordsDict.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the word frequence in spam email\n",
    "for file_name in spamFileList:\n",
    "    wordsList.clear()\n",
    "    with open('../data/spam/' + file_name, 'r', encoding='gbk') as f:\n",
    "        content = f.read()\n",
    "        for line in content:\n",
    "            rule = re.compile(u'[^\\u4E00-\\u9FA5]')\n",
    "            line = rule.sub(r'', line)\n",
    "            spam.get_word_list(line, wordsList, stop_list)\n",
    "    \n",
    "    spam.addToDict(wordsList, wordsDict)\n",
    "\n",
    "spamDict = wordsDict.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the word frequence in test email\n",
    "for file_name in testFileList:\n",
    "    testDict.clear()\n",
    "    wordsDict.clear()\n",
    "    wordsList.clear()\n",
    "    with open('../data/test/' + file_name, 'r', encoding='gbk') as f:\n",
    "        content = f.read()\n",
    "        for line in content:\n",
    "            rule = re.compile(u'[^\\u4E00-\\u9FA5]')\n",
    "            line = rule.sub(r'', line)\n",
    "            spam.get_word_list(line, wordsList, stop_list)\n",
    "    \n",
    "    spam.addToDict(wordsList, wordsDict)\n",
    "    testDict = wordsDict.copy()\n",
    "    \n",
    "    # Get the top 15 words according to the P(s|w) in each test email\n",
    "    word_prob_list = spam.get_test_words(testDict, spamDict, normDict, normFileLen, spamFileLen)\n",
    "  \n",
    "    # Compute the probability by naive bayes method\n",
    "    p = spam.calBayes(word_prob_list)\n",
    "    \n",
    "    # Set category tag for each test email\n",
    "    if (p > 0.9):\n",
    "        testResult.setdefault(file_name, 1)\n",
    "    else:\n",
    "        testResult.setdefault(file_name, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5076530612244898\n"
     ]
    }
   ],
   "source": [
    "# Compute the test accuracy\n",
    "# the file name lower than 1000 are normal email in test files\n",
    "testAccuracy = spam.calAccuracy(testResult)\n",
    "# for file, cat in testResult.items():\n",
    "#     print(file + '/' + str(cat))\n",
    "print(testAccuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
